{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6ecff74",
   "metadata": {},
   "source": [
    "<img src=\"https://www.th-koeln.de/img/logo.svg\" style=\"float:right;\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e683e302",
   "metadata": {},
   "source": [
    "# 8th exercise: <font color=\"#C70039\">Work with a regular Generative Adversarial Network (GAN)</font>\n",
    "* Course: AML\n",
    "* Lecturer: <a href=\"https://www.gernotheisenberg.de/\">Gernot Heisenberg</a>\n",
    "* Author of notebook: <a href=\"https://www.gernotheisenberg.de/\">Gernot Heisenberg</a>\n",
    "* Date:   15.10.2024\n",
    "\n",
    "<img src=\"https://hubert0527.github.io/COCO-GAN/images/teaser.png\" style=\"float: center;\" width=\"600\">\n",
    "\n",
    "---------------------------------\n",
    "**GENERAL NOTE 1**: \n",
    "Please make sure you are reading the entire notebook, since it contains a lot of information on your tasks (e.g. regarding the set of certain paramaters or a specific computational trick), and the written mark downs as well as comments contain a lot of information on how things work together as a whole. \n",
    "\n",
    "**GENERAL NOTE 2**: \n",
    "* Please, when commenting source code, just use English language only. \n",
    "* When describing an observation please use English language, too.\n",
    "* This applies to all exercises throughout this course.\n",
    "\n",
    "---------------------------------\n",
    "\n",
    "### <font color=\"ce33ff\">DESCRIPTION</font>:\n",
    "The code implements a regular GAN that generates images using a random latent vector as input. While it works great we do not know the mapping of latent vector to the generated image.\n",
    "\n",
    "Conditional GANs, however, can be used to supply a label during taining so the latent vector can be associated with a specific label - making the generation of images predictable. \n",
    "\n",
    "The below coded GAN is using the so-called cifar10 data set, which is standard to many machine learning applications (60,000 32x32 color images in 10 different classes: CIFAR10 classes are: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck).\n",
    "Following the code trains and generates images based on that cifar10 data set, that is included in the Keras package. \n",
    "Further information on the data set can be found here: <a href=\"https://en.wikipedia.org/wiki/CIFAR-10\"> cifar10 data set (wiki)</a>\n",
    "\n",
    "The code is adapted from the code by Jason Brownlee from his blogs on <a href=\"https://machinelearningmastery.com/\">https://machinelearningmastery.com/</a>.\n",
    "I seriously urge everyone to follow his blogs and get inspired. Hence, original credit goes to Jason Brownlee. \n",
    "\n",
    "---------------------------------\n",
    "\n",
    "### <font color=\"FFC300\">TASKS</font>:\n",
    "The tasks that you need to work on within this notebook are always indicated below as bullet points. \n",
    "If a task is more challenging and consists of several steps, this is indicated as well. \n",
    "Make sure you have worked down the task list and commented your doings. \n",
    "This should be done by using markdown.<br> \n",
    "<font color=red>Make sure you don't forget to specify your name and your matriculation number in the notebook.</font>\n",
    "\n",
    "**YOUR TASKS in this exercise are as follows**:\n",
    "1. import the notebook to Google Colab or use your local machine.\n",
    "2. make sure you specified you name and your matriculation number in the header below my name and date. \n",
    "    * set the date too and remove mine.\n",
    "3. read the entire notebook carefully \n",
    "    * add comments whereever you feel it necessary for better understanding\n",
    "    * run the notebook for the first time. \n",
    "4. train the GAN with a higher dimension of the latent space and over more epochs. Are the results improving? \n",
    "5. What could be done to further improve the quality of the generated images? \n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb1940",
   "metadata": {},
   "source": [
    "### GAN\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da1e5190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "\n",
    "# this import is needed because there is a problem with the Secure Socket Layer (SSL) certificate, \n",
    "# It can be resolved using the below line of code\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a2751",
   "metadata": {},
   "source": [
    "### Build the GAN architeture\n",
    "\n",
    "Use the \"functional\" way of defining the model for the conditional gan but use \"sequential\" for descriminator and generator as they are straight forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23043435",
   "metadata": {},
   "source": [
    "#### Define the standalone discriminator model\n",
    "\n",
    "Given an input image, the Discriminator outputs the likelihood of the image being real.\n",
    "Binary classification - true or false (1 or 0). So use the sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f7812e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 16, 16, 128)       3584      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 159,361\n",
      "Trainable params: 159,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def define_discriminator(in_shape=(32,32,3)):\n",
    "    model = Sequential(name=\"discriminator\")\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same', input_shape=in_shape)) #16x16x128\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same')) #8x8x128\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Flatten()) #shape of 8192\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid')) #shape of 1\n",
    "    \n",
    "    # Compile model since it is going to be trained directly and choose the optimizer\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "test_discriminator = define_discriminator()\n",
    "print(test_discriminator.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ad9d0",
   "metadata": {},
   "source": [
    "#### Define the standalone generator model\n",
    "Given the latent vector input, the Generator produces an image.(here: 32x32)\n",
    "The latent_dim, for example, can be 100, 1D array of size 100. \n",
    "\n",
    "Only Dense and conv2dlayers are being used. But the network can be more complicated based on the problem you are trying to solve. For example, you can use VGG as the basis for a super resolution GAN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fba7cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 8192)              827392    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8192)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 16, 16, 128)      262272    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 128)      262272    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 3)         24579     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,376,515\n",
      "Trainable params: 1,376,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#latent_dim is the dimension of the latent vector (e.g., 100 - see below)\n",
    "def define_generator(latent_dim):    \n",
    "    \n",
    "    model = Sequential(name=\"generator\")\n",
    "\n",
    "    # Reshape the input latent vector into an 8x8 image as a starting point. \n",
    "    # Hence n_nodes for the Dense layer are e.g. 128x8x8, so when reshaping the output \n",
    "    # it would be 8x8x128 and that can be slowly upscaled to a 32x32 image as the output.\n",
    "    n_nodes = 128 * 8 * 8  #8192 nodes\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim)) #Dense layer so we can work with a 1D latent vector\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((8, 8, 128)))  #8x8x128 data set from the latent vector. \n",
    "    # upsample to 16x16\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')) #16x16x128\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # upsample to 32x32\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')) #32x32x128\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # generate\n",
    "    model.add(Conv2D(3, (8,8), activation='tanh', padding='same')) #32x32x3\n",
    "    return model  # the generator model not compiled as it is not directly trained as the discriminator.\n",
    "                  # the generator is being trained via a GAN combined model (see below)\n",
    "\n",
    "test_generator = define_generator(latent_dim=100)\n",
    "print(test_generator.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcecc766",
   "metadata": {},
   "source": [
    "Now, define the combined generator and discriminator model, for updating the generator.\n",
    "The discriminator is trained separately so here only the generator will be trained by keeping the discriminator constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c58faac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_gan(generator, discriminator):\n",
    "    # The discriminator is trained separately (see above). Hence, set it to not trainable.\n",
    "    discriminator.trainable = False  \n",
    "    \n",
    "    # Now, connect the generator and the discriminator\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    \n",
    "    # Compile the combined model and Choose an optimizer\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe4977b",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Load the data set and plot parts of it in order to get a quick understanding.\n",
    "\n",
    "CIFAR10 classes are: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de710b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(trainX, trainy), (testX, testy) = load_data()\n",
    "\n",
    "# plot 25=5x5 example images\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, 1 + i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(trainX[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47265cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the cifar images and build a training data set\n",
    "def load_real_samples():\n",
    "    (trainX, _), (_, _) = load_data()\n",
    "    # convert to float and scale.\n",
    "    X = trainX.astype('float32')\n",
    "    # the generator uses tanh as activation function (see above), \n",
    "    # so we need to rescale from [0,255] to [-1,1]\n",
    "    # original images to -1 to 1 to match the output of generator.\n",
    "    X = (X - 127.5) / 127.5  \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cbd1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pick a batch of random real samples to train the GAN\n",
    "# In fact, train the GAN on a half batch of real images and another half batch of fake images. \n",
    "# For each real image assign the label=1 and for fake assign the label=0. \n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random images\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # select the random images and assign it to X\n",
    "    x = dataset[ix]\n",
    "    # generate class labels and assign to y\n",
    "    y = ones((n_samples, 1)) # label=1 indicates that the image is a real one\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698be62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate n_samples number of latent vectors as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c08c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the generator to generate n fake examples, with class labels\n",
    "# Supply the generator, latent_dim and number of samples as input.\n",
    "# Use the above latent point generator to generate latent points. \n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict using generator to generate fake samples. \n",
    "    x = generator.predict(x_input)\n",
    "    # Class labels will be 0 as these samples are fake. \n",
    "    y = zeros((n_samples, 1))  # label=0 indicates that the image is a fake one\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a2c93f",
   "metadata": {},
   "source": [
    "### Training function for the generator and discriminator\n",
    "Loop through a number of epochs to train the discriminator by first selecting a random batch of images from the true/real data set. Then, generate a set of images using the generator. Feed both sets of images into the discriminator. Finally, set the loss parameters for both the real and fake images, as well as the combined loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d406b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, filename, dataset, latent_dim, n_epochs=100, n_batch=128):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)  #the discriminator model is updated for a half batch of real samples \n",
    "                            #and a half batch of fake samples, combined a single batch. \n",
    "    # manually enumerate epochs and bacthes. \n",
    "    for i in range(n_epochs):\n",
    "        # enumerate batches over the training set\n",
    "        for j in range(bat_per_epo):\n",
    "            \n",
    "            # Train the discriminator on real and fake images, separately (half batch each)\n",
    "            #Research showed that separate training is more effective. \n",
    "            # get randomly selected 'real' samples\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            # update discriminator model weights\n",
    "            ##train_on_batch allows you to update weights based on a collection \n",
    "            #of samples you provide\n",
    "            #Let us just capture loss and ignore accuracy value (2nd output below)\n",
    "            d_loss_real, _ = d_model.train_on_batch(X_real, y_real) \n",
    "            \n",
    "            # generate 'fake' examples\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            # update discriminator model weights\n",
    "            d_loss_fake, _ = d_model.train_on_batch(X_fake, y_fake)\n",
    "            \n",
    "            #d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) #Average loss if you want to report single..\n",
    "            \n",
    "            # prepare points in latent space as input for the generator\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "             \n",
    "            # The generator wants the discriminator to label the generated samples as valid ones.\n",
    "            # This is where the generator is trying to trick discriminator into believing that \n",
    "            # the generated image is true (hence value of 1 for y)\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            \n",
    "            # The generator is part of the combined model where it got directly linked with the discriminator\n",
    "            # Train the generator with latent_dim as x and 1 as y. \n",
    "            # Again, 1 as the output as it is adversarial and if the generator did a great\n",
    "            # job of fooling the discriminator, then the output would be 1 (true).\n",
    "            # Update the generator via the discriminator's error\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            \n",
    "            # Print losses on this batch\n",
    "            print('Epoch=',i+1, 'Batch=', j+1, '/',bat_per_epo, 'd1=', d_loss_real, 'd2=', d_loss_fake, 'g=', g_loss)\n",
    "    \n",
    "    # save the generator model\n",
    "    g_model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3638625",
   "metadata": {},
   "source": [
    "### Train the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4213e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "# train model\n",
    "n_epochs=5 #50\n",
    "model_filename = \"cifar_GAN.\" + str(n_epochs) + \"_epochs.keras\"\n",
    "train(generator, discriminator, gan_model, model_filename, dataset, latent_dim, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a000f625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now, load the generator model and generate images\n",
    "\n",
    "# Plot generated images function\n",
    "def show_plot(examples, n):\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(examples[i, :, :, :])\n",
    "    plt.show()\n",
    "\n",
    "# load model\n",
    "model = load_model(model_filename) #Model trained for n epochs\n",
    "\n",
    "# generate the latent vector \n",
    "latent_points = generate_latent_points(100, 25)  #Latent dim and n_samples\n",
    "\n",
    "# generate images from the latent vector \n",
    "X = model.predict(latent_points)\n",
    "\n",
    "# scale from [-1,1] to [0,1]\n",
    "X = (X + 1) / 2.0\n",
    "X = (X*255).astype(np.uint8)\n",
    "\n",
    "# plot the generated images\n",
    "# Note: CIFAR10 classes are: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "show_plot(X, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
